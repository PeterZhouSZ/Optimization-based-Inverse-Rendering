{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import sys\n",
    "import math\n",
    "from scipy.io import loadmat\n",
    "from scipy.special import sph_harm\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from autograd import jacobian, grad\n",
    "import autograd\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_fitting(object):\n",
    "    def __init__(self, h, w, use_gpu=True):\n",
    "        self.no_of_ver = 53215\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.use_gpu = use_gpu\n",
    "        self.p_mu = None\n",
    "        self.b_mu = None\n",
    "        self.A_alb = None\n",
    "        self.A_id = None\n",
    "        self.A_exp = None\n",
    "        self.std_id = None\n",
    "        self.std_alb = None\n",
    "        self.std_exp = None\n",
    "        self.chi = np.random.randn(312,1)\n",
    "        self.chi_final = None\n",
    "        self.I_in = None\n",
    "        self.I_rend = None\n",
    "        self.tri_mesh_data = None\n",
    "        self.lmks={}\n",
    "        self.no_of_lmks = None\n",
    "        self.no_of_face_pixels = None\n",
    "        self.verteex = None\n",
    "        self.albedo = None\n",
    "        self.J = None\n",
    "        self.load_data()\n",
    "        \n",
    "        \n",
    "    '''Function to load .pts file. Landmarks for 300W dataset are stored in .pts format'''\n",
    "    def load(self,path):\n",
    "        \"\"\"takes as input the path to a .pts and returns a list of \n",
    "        tuples of floats containing the points in in the form:\n",
    "        [(x_0, y_0, z_0),\n",
    "         (x_1, y_1, z_1),\n",
    "         ...\n",
    "         (x_n, y_n, z_n)]\"\"\"\n",
    "        with open(path) as f:\n",
    "            rows = [rows.strip() for rows in f]\n",
    "\n",
    "        \"\"\"Use the curly braces to find the start and end of the point data\"\"\" \n",
    "        head = rows.index('{') + 1\n",
    "        tail = rows.index('}')\n",
    "\n",
    "        \"\"\"Select the point data split into coordinates\"\"\"\n",
    "        raw_points = rows[head:tail]\n",
    "        coords_set = [point.split() for point in raw_points]\n",
    "\n",
    "        \"\"\"Convert entries from lists of strings to tuples of floats\"\"\"\n",
    "        points = [tuple([float(point) for point in coords]) for coords in coords_set]\n",
    "        return points\n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "        '''Function to load all the necessary data\n",
    "        Prinicpal components, standard deviations, input image, triangle mesh data, landmarks'''\n",
    "        \n",
    "        #Expression parameters\n",
    "        fileName='Dataset/Coarse_Dataset/Exp_Pca.bin'\n",
    "        with open(fileName, mode='rb') as file: # b is important -> binary\n",
    "        #     fileContent = file.read()\n",
    "            dim_exp = np.fromfile(file, dtype=np.int32, count=1)\n",
    "            mu_exp = np.zeros(self.no_of_ver*3)\n",
    "            base_exp = np.zeros((self.no_of_ver*3,dim_exp[0]), dtype=float)\n",
    "            mu_exp = np.fromfile(file, dtype=float, count=3*self.no_of_ver)\n",
    "            base_exp = np.fromfile(file, dtype=float, count=3*self.no_of_ver*dim_exp[0])\n",
    "        self.A_exp = np.array(np.resize(base_exp, (self.no_of_ver*3, dim_exp[0])))\n",
    "        \n",
    "        data = np.loadtxt('Dataset/Coarse_Dataset/std_exp.txt', delimiter=' ')\n",
    "        data=data[:,np.newaxis]\n",
    "        self.std_exp = np.array(data)\n",
    "        \n",
    "        #Triangle mesh data\n",
    "        temp = loadmat('Dataset/3DDFA_Release/Matlab/ModelGeneration/model_info.mat')\n",
    "        trimIndex = np.array(temp['trimIndex'][:,0], dtype=np.int32)\n",
    "        trim_ind = np.reshape(np.array([3*trimIndex-2,3*trimIndex-1,3*trimIndex])-1,(self.no_of_ver*3,),'F')#np.append(3*trimIndex-2,np.append( 3*trimIndex-1, 3*trimIndex))\n",
    "        self.tri_mesh_data = temp['tri'].T - 1\n",
    "        \n",
    "        #3D and 2D landmarks data\n",
    "        lmks_3d_ind = temp['keypoints']\n",
    "        lmks_2d = np.array(self.load('Dataset/300W-Convert/300W-Original/afw/134212_1.pts'))\n",
    "        self.no_of_lmks = len(lmks_2d)\n",
    "        self.lmks['2d'] = lmks_2d-[700,144]\n",
    "        self.lmks['3d'] = lmks_3d_ind\n",
    "        self.no_of_face_pixels = len(lmks_3d_ind)\n",
    "        \n",
    "        #Identity and Albedo parameters\n",
    "        morph_model = loadmat('Dataset/PublicMM1/01_MorphableModel.mat')\n",
    "        shapePCA = morph_model['shapePC']\n",
    "        shapeMU = morph_model['shapeMU']\n",
    "        shapeSTD = morph_model['shapeEV']\n",
    "\n",
    "        texPCA = morph_model['texPC']\n",
    "        texMU = morph_model['texMU']\n",
    "        texSTD = morph_model['texEV']\n",
    "        \n",
    "        self.p_mu = shapeMU[trim_ind]\n",
    "        self.b_mu = texMU[trim_ind]\n",
    "        self.A_alb = np.array(texPCA[trim_ind,:100])\n",
    "        self.A_id = np.array(shapePCA[trim_ind,:100])\n",
    "        self.std_id = np.array(shapeSTD[:100])\n",
    "        self.std_alb = np.array(texSTD[:100])\n",
    "        \n",
    "        #Input image\n",
    "        I_in = plt.imread('Dataset/300W-Convert/300W-Original/afw/134212_1.jpg')\n",
    "        self.I_in=I_in[144:400,700:956,:]\n",
    "        \n",
    "        #Approximate estimation of number of face pixels using first 17 landmarks\n",
    "        polygon = Polygon(self.lmks['2d'][:17,:])\n",
    "        temp2 = np.empty((self.h,self.w))\n",
    "        for i in range(self.h):\n",
    "            for j in range(self.w):\n",
    "                point = Point(i,j)\n",
    "                temp2[i,j] = polygon.contains(point)\n",
    "        self.no_of_face_pxls = np.sum(temp2==1)\n",
    "    \n",
    "    '''To calculate Associated Legendre Polynomial'''\n",
    "    def P(self, l, m, x):\n",
    "        pmm = 1.0\n",
    "        if m>0:\n",
    "            somx2 = np.sqrt((1.0-x)*(1.0+x))\n",
    "            fact = 1.0\n",
    "            for i in range(m):\n",
    "                pmm = -fact*pmm*somx2\n",
    "                fact = fact+2.0\n",
    "        if l==m :\n",
    "            return pmm\n",
    "        pmmp1 = x*(2.0*m+1.0)*pmm\n",
    "        if (l==m+1):\n",
    "            return pmmp1\n",
    "        pll = 0.0\n",
    "        for ll in range(m+2, l+1):\n",
    "            pll = ((2.0*ll-1.0)*x*pmmp1 - (ll+m-1.0)*pmm)/(ll-m)\n",
    "            pmm = pmmp1\n",
    "            pmmp1 = pll\n",
    "        return pll\n",
    "\n",
    "    def factorial(self,n):\n",
    "        return np.prod(range(1,n+1))\n",
    "\n",
    "    def K(self, l, m):\n",
    "        norm_const = ((2.0*l+1.0)*self.factorial(l-m))/((4.0*np.pi)*self.factorial(l+m))\n",
    "        return np.sqrt(norm_const)\n",
    "    \n",
    "    '''To calculate spherical harmonics(since scipy.special.sph_harm does not work with autograd.numpy)'''\n",
    "    def SH(self, m, l, phi, theta):\n",
    "        '''http://silviojemma.com/public/papers/lighting/spherical-harmonic-lighting.pdf'''\n",
    "        sqrt2 = np.sqrt(2.0)\n",
    "        if m==0:\n",
    "            return self.K(l,0)*self.P(l,m,np.cos(theta))\n",
    "        elif m>0:\n",
    "            return sqrt2*self.K(l,m)*np.cos(m*phi)*self.P(l,m,np.cos(theta))\n",
    "        else:\n",
    "            return sqrt2*self.K(l,-m)*np.sin(-m*phi)*self.P(l,-m,np.cos(theta))\n",
    "    \n",
    "    '''To calculate first 3 bands of spherical harmonics'''\n",
    "#     def sh_basis_scipy(self, n):\n",
    "#         theta = n[1] #Polar angle\n",
    "#         phi = n[0] #Azimuth angle\n",
    "#         sh = np.zeros((9,), dtype=np.float32)\n",
    "#         count = 0\n",
    "#         for l in range(3):\n",
    "#             for m in np.arange(-l,l+1):\n",
    "#                 if m==0:\n",
    "#                     sh[count]=np.real(sph_harm(m,l,phi,theta))\n",
    "#                 elif m>0:\n",
    "#                     sh[count]=np.sqrt(2)*np.real(sph_harm(m,l,phi,theta))\n",
    "#                 else:\n",
    "#                     sh[count]=np.sqrt(2)*np.imag(sph_harm(m,l,phi,theta))\n",
    "#                 count = count+1\n",
    "            \n",
    "#         return sh\n",
    "    \n",
    "    def sh_basis(self,n):\n",
    "        theta = n[1] #Polar angle\n",
    "        phi = n[0] #Azimuth angle\n",
    "        sh = np.zeros((9,), dtype=np.float32)\n",
    "        count = 0\n",
    "        return np.array([self.SH(m,l,phi,theta) for l in range(3) for m in range(-l,l+1) ])\n",
    "    \n",
    "    '''To calculate rotational matrix from pitch yaw and roll'''\n",
    "    def rot_mat(self, pitch, yaw, roll):\n",
    "        Rx = np.array([[1,0,0],\n",
    "                       [0,np.cos(roll),-np.sin(roll)],\n",
    "                       [0,np.sin(roll),np.cos(roll)]])\n",
    "        Ry = np.array([[np.cos(pitch),0,np.sin(pitch)],\n",
    "                       [0,1,0],\n",
    "                       [-np.sin(pitch),0,np.cos(pitch)]])\n",
    "        Rz = np.array([[np.cos(yaw),-np.sin(yaw),0],\n",
    "                       [np.sin(yaw),np.cos(yaw),0],\n",
    "                       [0,0,1]])\n",
    "        R = Rz@Ry@Rx\n",
    "\n",
    "        return R\n",
    "    \n",
    "    '''To convert world coordinates to image coordinates'''\n",
    "    def world_to_image(self, q_world):\n",
    "        temp_q = np.array(q_world, copy=True)\n",
    "        temp = np.array([self.w/2,self.h/2-self.h+1,0])\n",
    "        q_image = (q_world + temp)*[1,-1,1]\n",
    "\n",
    "    #     q_image[:,0] = q_image[:,0] + w/2\n",
    "    #     q_image[:,1] = q_image[:,1] + h/2\n",
    "    #     q_image[:,1] = h - q_image[:,1] - 1\n",
    "\n",
    "        return q_image\n",
    "    \n",
    "    '''Cartesian coordinates to spherical coordinates'''\n",
    "    def cart2sph(self, n):\n",
    "        temp = n[1]/n[0]\n",
    "\n",
    "        if n[0]==0:\n",
    "            if n[1]<0:\n",
    "                phi = -np.pi/2\n",
    "            else:\n",
    "                phi = np.pi/2\n",
    "        else:\n",
    "            if n[0]>0:\n",
    "                phi = np.arctan(temp)\n",
    "            elif n[1]<0:\n",
    "                phi = np.arctan(temp) - np.pi\n",
    "            else:\n",
    "                phi = np.arctan(temp) + np.pi\n",
    "    #     phi = np.arctan() #arctan(y/x)\n",
    "        theta = np.arccos(n[2]) #arccos(z)\n",
    "\n",
    "        return [phi, theta]\n",
    "    \n",
    "    '''Calculate normal of triangle for each pixel based on underlying triangle index'''\n",
    "    def calculate_normal(self, tri_ind_info, centroid, q):\n",
    "    #     normal_xyz = np.zeros((h, w, 3))\n",
    "    #     normal_sph = np.zeros((h, w, 2))\n",
    "        normal_xyz = {}\n",
    "        normal_sph = {}\n",
    "\n",
    "        for i in range(self.h):\n",
    "            for j in range(self.w):\n",
    "                normal_xyz[(i,j)] = 0\n",
    "                normal_sph[(i,j)] = 0\n",
    "                tri_ver = q[self.tri_mesh_data[tri_ind_info[i, j]-1, :],:]\n",
    "                a = tri_ver[0,:]\n",
    "                b = tri_ver[1,:]\n",
    "                c = tri_ver[2,:]\n",
    "                normal_xyz[(i,j)] = np.cross(a-b, b-c)/np.linalg.norm(np.cross(a-b, b-c))\n",
    "                if np.dot(np.mean(tri_ver, 0)-centroid, normal_xyz[(i,j)])<0:\n",
    "                    normal_xyz[(i,j)] *= -1\n",
    "                normal_sph[(i,j)] = self.cart2sph(normal_xyz[(i,j)])\n",
    "        return normal_sph\n",
    "    \n",
    "    def isPointInTri(self, point, tri_points):\n",
    "        ''' Judge whether the point is in the triangle\n",
    "        Method:\n",
    "            http://blackpawn.com/texts/pointinpoly/\n",
    "        Args:\n",
    "            point: (2,). [u, v] or [x, y] \n",
    "            tri_points: (3 vertices, 2 coords). three vertices(2d points) of a triangle. \n",
    "        Returns:\n",
    "            bool: true for in triangle\n",
    "        '''\n",
    "        tp = tri_points\n",
    "\n",
    "        # vectors\n",
    "        v0 = tp[2,:] - tp[0,:]\n",
    "        v1 = tp[1,:] - tp[0,:]\n",
    "        v2 = point - tp[0,:]\n",
    "\n",
    "        # dot products\n",
    "        dot00 = np.dot(v0.T, v0)\n",
    "        dot01 = np.dot(v0.T, v1)\n",
    "        dot02 = np.dot(v0.T, v2)\n",
    "        dot11 = np.dot(v1.T, v1)\n",
    "        dot12 = np.dot(v1.T, v2)\n",
    "\n",
    "        # barycentric coordinates\n",
    "        if dot00*dot11 - dot01*dot01 == 0:\n",
    "            inverDeno = 0\n",
    "        else:\n",
    "            inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "        u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "        v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "        # check if point in triangle\n",
    "        return (u >= 0) & (v >= 0) & (u + v < 1)\n",
    "\n",
    "    '''To estimate the barycentric weights of a point given that it is inside a triangle\n",
    "    The barycentric weights are used later to estimate albedo by barycentric interpolation'''\n",
    "    def get_point_weight(self, point, tri_points):\n",
    "        ''' Get the weights of the position\n",
    "        Methods: https://gamedev.stackexchange.com/questions/23743/whats-the-most-efficient-way-to-find-barycentric-coordinates\n",
    "         -m1.compute the area of the triangles formed by embedding the point P inside the triangle\n",
    "         -m2.Christer Ericson's book \"Real-Time Collision Detection\". faster.(used)\n",
    "        Args:\n",
    "            point: (2,). [u, v] or [x, y] \n",
    "            tri_points: (3 vertices, 2 coords). three vertices(2d points) of a triangle. \n",
    "        Returns:\n",
    "            w0: weight of v0\n",
    "            w1: weight of v1\n",
    "            w2: weight of v3\n",
    "         '''\n",
    "        tp = tri_points\n",
    "        # vectors\n",
    "        v0 = tp[2,:] - tp[0,:]\n",
    "        v1 = tp[1,:] - tp[0,:]\n",
    "        v2 = point - tp[0,:]\n",
    "\n",
    "        # dot products\n",
    "        dot00 = np.dot(v0.T, v0)\n",
    "        dot01 = np.dot(v0.T, v1)\n",
    "        dot02 = np.dot(v0.T, v2)\n",
    "        dot11 = np.dot(v1.T, v1)\n",
    "        dot12 = np.dot(v1.T, v2)\n",
    "\n",
    "        # barycentric coordinates\n",
    "        if dot00*dot11 - dot01*dot01 == 0:\n",
    "            inverDeno = 0\n",
    "        else:\n",
    "            inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "        u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "        v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "        w0 = 1 - u - v\n",
    "        w1 = v\n",
    "        w2 = u\n",
    "\n",
    "        return w0, w1, w2\n",
    "\n",
    "    '''Rasterization to find underlying triangle index and barycentrics weights of each pixel'''\n",
    "    def rasterize_triangles(self, vertices):\n",
    "        ''' \n",
    "        Args:\n",
    "            vertices: [nver, 3]\n",
    "            triangles: [ntri, 3]\n",
    "            h: height\n",
    "            w: width\n",
    "        Returns:\n",
    "            depth_buffer: [h, w] saves the depth, here, the bigger the z, the fronter the point.\n",
    "            triangle_buffer: [h, w] saves the tri id(-1 for no triangle). \n",
    "            barycentric_weight: [h, w, 3] saves corresponding barycentric weight.\n",
    "\n",
    "        # Each triangle has 3 vertices & Each vertex has 3 coordinates x, y, z.\n",
    "        # h, w is the size of rendering\n",
    "        '''\n",
    "        # initial \n",
    "        depth_buffer = {}#np.zeros([h, w]) - 999999. #+ np.min(vertices[2,:]) - 999999. # set the initial z to the farest position\n",
    "        triangle_buffer = np.zeros([self.h, self.w], dtype = np.int32) - 1  # if tri id = -1, the pixel has no triangle correspondance\n",
    "        barycentric_weight = {}#np.zeros([h, w, 3], dtype = np.float32)  # \n",
    "\n",
    "        for i in range(self.h):\n",
    "            for j in range(self.w):\n",
    "                depth_buffer[(i,j)] = -math.inf\n",
    "                barycentric_weight[(i,j)] = np.array([0, 0, 0])\n",
    "\n",
    "        for i in range(self.tri_mesh_data.shape[0]):\n",
    "    #         print('Rasterzing: ',i+1)\n",
    "            tri = self.tri_mesh_data[i, :] # 3 vertex indices\n",
    "\n",
    "            # the inner bounding box\n",
    "            umin = max(int(np.ceil(np.min(vertices[tri, 0]))), 0)\n",
    "            umax = min(int(np.floor(np.max(vertices[tri, 0]))), self.w-1)\n",
    "\n",
    "            vmin = max(int(np.ceil(np.min(vertices[tri, 1]))), 0)\n",
    "            vmax = min(int(np.floor(np.max(vertices[tri, 1]))), self.h-1)\n",
    "\n",
    "            if umax<umin or vmax<vmin:\n",
    "                continue\n",
    "\n",
    "            for u in range(umin, umax+1):\n",
    "                for v in range(vmin, vmax+1):\n",
    "                    if not self.isPointInTri([u,v], vertices[tri, :2]): \n",
    "                        continue\n",
    "                    w0, w1, w2 = self.get_point_weight([u, v], vertices[tri, :2]) # barycentric weight\n",
    "                    point_depth = w0*vertices[tri[0], 2] + w1*vertices[tri[1], 2] + w2*vertices[tri[2], 2]\n",
    "                    if point_depth > depth_buffer[v, u]:\n",
    "                        depth_buffer[(v, u)] = point_depth\n",
    "                        triangle_buffer[v, u] = i\n",
    "                        barycentric_weight[(v, u)] = np.array([w0, w1, w2])\n",
    "\n",
    "        return depth_buffer, triangle_buffer, barycentric_weight\n",
    "    \n",
    "    '''Function to render image given 3D vertices, albedo and spherical harmonic coefficients for lighting'''\n",
    "    def render_color_image(self, q, albedo, gamma):\n",
    "    #     image = np.zeros((h,w,3), dtype=np.float32)\n",
    "        centroid = np.mean(q,0)\n",
    "\n",
    "    #     tri_ind_info, bary_wts_info = rasterize(q[:,:2], q[:,2], tri_mesh_data, h, w)\n",
    "        st = time()\n",
    "        depth_info, tri_ind_info, bary_wts_info = self.rasterize_triangles(q)\n",
    "        print(time()-st)\n",
    "\n",
    "        n_sph = self.calculate_normal(tri_ind_info, centroid, q)\n",
    "\n",
    "    #     for i in range(h):\n",
    "    #         for j in range(w):\n",
    "    #             sh_func = sh_basis(n_sph[(i,j)])\n",
    "    #             alb[i,j,:] = (albedo[tri_mesh_data[tri_ind_info[i, j], :],:].T@bary_wts_info[(i,j)])*(gamma.T@sh_func.squeeze())\n",
    "    #             image[i,j,:] = alb[i,j,:]*(gamma.T@sh_func.squeeze())\n",
    "    \n",
    "        image = np.array([[(albedo[self.tri_mesh_data[tri_ind_info[i, j], :],:].T@bary_wts_info[(i,j)])*(gamma.T@self.sh_basis((n_sph[(i,j)])).squeeze()) for j in range(self.w)] for i in range(self.h)])\n",
    "        return image\n",
    "    \n",
    "    '''To calculate vertex and albedo from prinipal components and mean shape and albedo parameters'''\n",
    "    def cal_ver_alb(self, al_id, al_exp, al_alb):\n",
    "        p = self.p_mu + self.A_id@al_id + self.A_exp@al_exp\n",
    "        b = self.b_mu + self.A_alb@al_alb\n",
    "        self.vertex = np.reshape(p, (self.no_of_ver, 3))\n",
    "        self.albedo = np.reshape(b, (self.no_of_ver, 3))\n",
    "    \n",
    "    '''To calculate the objective function as mentioned in the paper'''\n",
    "    def E(self, chi):\n",
    "        al_id = chi[0:100]\n",
    "        al_exp = chi[100:179]\n",
    "        al_alb = chi[179:279]\n",
    "        [s, pitch, yaw, roll] = chi[279:283,0]\n",
    "        t = chi[283:285]\n",
    "        r = chi[285:]\n",
    "        gamma = np.reshape(r,(9,3),'F')\n",
    "        lmks_2d = self.lmks['2d']\n",
    "        lmks_3d_ind = self.lmks['3d']\n",
    "\n",
    "        R = self.rot_mat(pitch, yaw, roll)\n",
    "\n",
    "        self.cal_ver_alb(al_id, al_exp, al_alb)\n",
    "        q_world = s*R@self.vertex.T\n",
    "        q_world[:2,:] = q_world[:2,:] + t\n",
    "        q_image = self.world_to_image(q_world.T)\n",
    "\n",
    "        I_rend = self.render_color_image(q_image, self.albedo, gamma)\n",
    "        self.I_rend = I_rend\n",
    "\n",
    "        w_l = 10\n",
    "        w_r = 5e-5\n",
    "        E_con = (1/self.no_of_face_pxls)*np.linalg.norm(I_rend - self.I_in)**2 #No of face pixels is apporximately 28241\n",
    "        E_lan = (1/self.no_of_lmks)*np.linalg.norm(lmks_2d - q_image[lmks_3d_ind[0,:],:2])**2 #68 landmarks\n",
    "        E_reg = np.linalg.norm(al_id/self.std_id)**2 + np.linalg.norm(al_alb/self.std_alb)**2 + np.linalg.norm(al_exp/self.std_exp)**2\n",
    "        \n",
    "        E_con_r = np.sqrt(1/self.no_of_face_pxls)*np.linalg.norm(I_rend-self.I_in)#np.reshape((I_rend-self.I_in),-1)#E_con + w_l*E_lan + w_r*E_reg\n",
    "        E_lan_r = np.sqrt(w_l/self.no_of_lmks)*np.linalg.norm(lmks_2d - q_image[lmks_3d_ind[0,:],:2], axis=1)#np.reshape((lmks_2d - q_image[lmks_3d_ind[0,:],:2]),-1)\n",
    "        E_reg_r = np.sqrt(w_r)*np.concatenate(((al_id/self.std_id),(al_alb/self.std_alb),(al_exp/self.std_exp)), axis = 0)\n",
    "        \n",
    "        return np.concatenate((np.array([E_con_r]),E_lan_r,E_reg_r[slice(None),0]), axis=0)\n",
    "    \n",
    "    '''Jacobian matrix estimation'''\n",
    "#     def Jaco(self, func, x, dx=10^-8):\n",
    "#         '''https://stackoverflow.com/questions/49553006/compute-the-jacobian-matrix-in-python'''\n",
    "        \n",
    "#         n = len(x)\n",
    "#         m = len(E_val)\n",
    "#         jac = np.zeros((m, n))\n",
    "#         for j in range(n): #through columns to allow for vector addition\n",
    "#             Dxj = (abs(x[j])*dx if x[j] != 0 else dx)\n",
    "#             x_plus = np.array([(xi if k != j else xi+Dxj) for k, xi in enumerate(x)])\n",
    "#             jac[:, j] = (self.E(x_plus)-func)/Dxj\n",
    "#         return jac\n",
    "    \n",
    "    def jacob(self,j,f,x,func,dx):\n",
    "#         print('x:',j)\n",
    "        Dxj = (abs(x[j])*dx if x[j] != 0 else dx)\n",
    "    #     x_plus = np.array([(xi if k != j else xi+Dxj) for k, xi in enumerate(x)]) \n",
    "        x_plus = x.copy()\n",
    "        x_plus[j] = x_plus[j] + Dxj\n",
    "        return (f(x_plus)-func)/Dxj\n",
    "    \n",
    "    def Gauss_Newton_optim(self):\n",
    "        chi_prev = self.chi.copy()\n",
    "#         jacobian_E = jacobian(self.E)\n",
    "        count = 1\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "        n = len(chi_prev)\n",
    "        dx = 1e-8\n",
    "        while True:\n",
    "    #     chi_prev[279] = 100/(np.max(vertex) - np.min(vertex))\n",
    "            \n",
    "            print(\"Iteration No: \", count)\n",
    "            if count==1:\n",
    "                self.cal_ver_alb(self.chi[0:100],self.chi[100:179],self.chi[179:279])\n",
    "                chi_prev[279,0] = 150/(np.max(self.vertex)-np.min(self.vertex))\n",
    "                E_val = self.E(chi_prev)\n",
    "            print('s:',chi_prev[279,0])\n",
    "#             J = jacobian_E(chi_prev)\n",
    "            \n",
    "#             self.J = self.Jaco(E_val, self.chi)\n",
    "            st=time()\n",
    "            results = np.array([Parallel(n_jobs=num_cores)(delayed(self.jacob)(j,obj.E,chi_prev,E_val,dx) for j in range(n))])\n",
    "            print('Parallelization time:', time()-st)\n",
    "            self.J = results.squeeze().T\n",
    "            chi_next = chi_prev - np.linalg.pinv(self.J.T@self.J)@self.J.T@E_val[:,np.newaxis]\n",
    "            E_val = self.E(chi_next)\n",
    "            print('Increment: ', np.linalg.norm(chi_next-chi_prev))\n",
    "            print('Loss: ',np.linalg.norm(E_val)**2)\n",
    "            chi_prev = chi_next\n",
    "            count=count+1\n",
    "            if np.linalg.norm(E_val)**2<100:\n",
    "                self.chi_final = chi_prev\n",
    "                break\n",
    "\n",
    "    def plot_rendered_image(self):\n",
    "        im = self.I_rend+np.abs(np.min(self.I_rend))\n",
    "        im = im/np.max(im)\n",
    "        plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=model_fitting(256,256)\n",
    "# J = obj.Gauss_Newton_optim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.cal_ver_alb(obj.chi[0:100],obj.chi[100:179],obj.chi[179:279])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.Gauss_Newton_optim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
