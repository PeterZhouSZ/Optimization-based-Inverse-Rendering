{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.special import sph_harm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "from torch.autograd.gradcheck import zero_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device(\"cuda\")\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_ver = 53215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load expression principal components'''\n",
    "fileName='Dataset/Coarse_Dataset/Exp_Pca.bin'\n",
    "with open(fileName, mode='rb') as file: # b is important -> binary\n",
    "#     fileContent = file.read()\n",
    "    dim_exp = np.fromfile(file, dtype=np.int32, count=1)\n",
    "    mu_exp = np.zeros(no_of_ver*3)\n",
    "    base_exp = np.zeros((no_of_ver*3*dim_exp[0]), dtype=float)\n",
    "    mu_exp = np.fromfile(file, dtype=np.float32, count=3*no_of_ver)\n",
    "    base_exp = np.fromfile(file, dtype=np.float32, count=3*no_of_ver*dim_exp[0])\n",
    "\n",
    "A_exp = torch.tensor(np.array(np.resize(base_exp, (no_of_ver*3, dim_exp[0]))), dtype=torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load standard deviation of expression'''\n",
    "data = np.loadtxt('Dataset/Coarse_Dataset/std_exp.txt', delimiter=' ')\n",
    "data = torch.tensor(data[:,np.newaxis], dtype = torch.float32,requires_grad =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Triangle mesh data and indices excluded based on 3DDFA'''\n",
    "temp = loadmat('Dataset/3DDFA_Release/Matlab/ModelGeneration/model_info.mat')\n",
    "temp['tri'].dtype = np.int16\n",
    "trimIndex = np.array(temp['trimIndex'][:,0], dtype=np.int32)\n",
    "trim_ind = np.reshape(np.array([3*trimIndex-2,3*trimIndex-1,3*trimIndex])-1,(no_of_ver*3,),'F')\n",
    "tri_mesh_data = temp['tri'].T#torch.tensor(temp['tri'].T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    \"\"\"takes as input the path to a .pts and returns a list of \n",
    "    tuples of floats containing the points in in the form:\n",
    "    [(x_0, y_0, z_0),\n",
    "     (x_1, y_1, z_1),\n",
    "     ...\n",
    "     (x_n, y_n, z_n)]\"\"\"\n",
    "    with open(path) as f:\n",
    "        rows = [rows.strip() for rows in f]\n",
    "\n",
    "    \"\"\"Use the curly braces to find the start and end of the point data\"\"\" \n",
    "    head = rows.index('{') + 1\n",
    "    tail = rows.index('}')\n",
    "\n",
    "    \"\"\"Select the point data split into coordinates\"\"\"\n",
    "    raw_points = rows[head:tail]\n",
    "    coords_set = [point.split() for point in raw_points]\n",
    "\n",
    "    \"\"\"Convert entries from lists of strings to tuples of floats\"\"\"\n",
    "    points = [tuple([float(point) for point in coords]) for coords in coords_set]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2D and 3D landmarks'''\n",
    "lmks_2d = torch.tensor(load('Dataset/300W-Convert/300W-Original/afw/134212_1.pts'))\n",
    "lmks_2d = lmks_2d - torch.tensor([700,144], dtype=torch.float32)\n",
    "lmks_3d_ind = np.array(temp['keypoints'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  1.1.0\n",
      "CUDA available:  True\n",
      "CUDA version:  9.0.176\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \", torch.__version__ )\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load mean shape and albedo parameters, princiapl components and standard deviations for identity and albedo'''\n",
    "morph_model = loadmat('Dataset/PublicMM1/01_MorphableModel.mat')\n",
    "\n",
    "shapePCA = morph_model['shapePC']\n",
    "shapeMU = morph_model['shapeMU']\n",
    "shapeSTD = morph_model['shapeEV']\n",
    "\n",
    "texPCA = morph_model['texPC']\n",
    "texMU = morph_model['texMU']\n",
    "texSTD = morph_model['texEV']\n",
    "\n",
    "p_mu = torch.tensor(shapeMU[trim_ind])\n",
    "b_mu = torch.tensor(texMU[trim_ind])\n",
    "A_alb = torch.tensor(texPCA[trim_ind,:100])\n",
    "A_id = torch.tensor(shapePCA[trim_ind,:100])\n",
    "std_id = torch.tensor(shapeSTD[:100])\n",
    "std_alb = torch.tensor(texSTD[:100])\n",
    "std_exp = data #Standard deviation of expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To calculate Legendre Polynomial'''\n",
    "def P(l, m, x):\n",
    "    pmm = 1.0\n",
    "    if m>0:\n",
    "        somx2 = torch.sqrt((1.0-x)*(1.0+x))\n",
    "        fact = 1.0\n",
    "        for i in torch.arange(m):\n",
    "            pmm = -fact*pmm*somx2\n",
    "            fact = fact+2.0\n",
    "    if l==m :\n",
    "        return pmm\n",
    "    pmmp1 = x*(2.0*m+1.0)*pmm\n",
    "    if (l==m+1):\n",
    "        return pmmp1\n",
    "    pll = 0.0\n",
    "    for ll in torch.arange(m+2, l+1):\n",
    "        pll = ((2.0*ll-1.0)*x*pmmp1 - (ll+m-1.0)*pmm)/(ll-m)\n",
    "        pmm = pmmp1\n",
    "        pmmp1 = pll\n",
    "    return pll\n",
    "\n",
    "def factorial(n):\n",
    "    return torch.prod(torch.arange(1,n+1), dtype=torch.float32)\n",
    "\n",
    "def K(l, m):\n",
    "    norm_const = ((2.0*l+1.0)*factorial(l-m))/((4.0*np.pi)*factorial(l+m))\n",
    "    return torch.sqrt(norm_const)\n",
    "\n",
    "'''To calculate spherical harmonics(scipy.special.sph_harm does not work with pytorch for creating computational graph)'''\n",
    "def SH(m, l, phi, theta):\n",
    "    sqrt2 = torch.sqrt(torch.tensor(2.0, dtype=torch.float32))\n",
    "    if m==0:\n",
    "        return K(l,0)*P(l,m,torch.cos(theta))\n",
    "    elif m>0:\n",
    "        return sqrt2*K(l,m)*torch.cos(m*phi)*P(l,m,torch.cos(theta))\n",
    "    else:\n",
    "        return sqrt2*K(l,-m)*torch.sin(-m*phi)*P(l,-m,torch.cos(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To calculate rotational matrix from pitch yaw and roll'''\n",
    "def rot_mat(pitch, yaw, roll):\n",
    "    Ry = torch.tensor([[torch.cos(pitch),0,torch.sin(pitch)],[0,1,0],[-torch.sin(pitch),0,torch.cos(pitch)]], requires_grad = True)\n",
    "    Rx = torch.tensor([[1,0,0],[0,torch.cos(roll),torch.sin(roll)],[0,-torch.sin(roll),torch.cos(roll)]], requires_grad = True)\n",
    "    Rz = torch.tensor([[torch.cos(yaw),torch.sin(yaw),0],[-torch.sin(yaw),torch.cos(yaw),0],[0,0,1]], requires_grad = True)\n",
    "    R = Rz@Ry@Rx\n",
    "    \n",
    "    return R\n",
    "\n",
    "'''To calculate first 3 bands of spherical harmonics'''\n",
    "def sh_basis(norm):\n",
    "#     if torch.is_tensor(n):\n",
    "#         norm = n.cpu().detach().numpy()\n",
    "#     else:\n",
    "#         norm = n\n",
    "    theta = norm[1] #Polar angle\n",
    "    phi = norm[0] #Azimuth angle\n",
    "    sh = torch.zeros((9,), dtype=torch.float32, requires_grad=True)\n",
    "    count = 0\n",
    "    for l in torch.arange(3):\n",
    "        for m in torch.arange(-l,l+1):\n",
    "#             if m==0:\n",
    "#                 sh[count]=np.real(sph_harm(m,l,phi,theta))\n",
    "#             elif m>0:\n",
    "#                 sh[count]=np.sqrt(2)*np.real(sph_harm(m,l,phi,theta))\n",
    "#             else:\n",
    "#                 sh[count]=np.sqrt(2)*np.imag(sph_harm(m,l,phi,theta))\n",
    "#             count = count+1\n",
    "                sh[count] = SH(m,l,phi,theta)\n",
    "                count = count+1\n",
    "            \n",
    "    return sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To estimate the barycentric weights of a point given that it is inside a triangle\n",
    "    The barycentric weights are used later to estimate albedo by barycentric interpolation'''\n",
    "def barycentric_weights(p, tri_p):\n",
    "    #http://blackpawn.com/texts/pointinpoly/\n",
    "    \n",
    "    a = tri_p[0,:]\n",
    "    b = tri_p[1,:]\n",
    "    c = tri_p[2,:]\n",
    "    \n",
    "    v0 = c - a\n",
    "    v1 = b - a\n",
    "    v2 = p - a\n",
    "    \n",
    "    dot00 = np.dot(v0, v0)\n",
    "    dot01 = np.dot(v0, v1)\n",
    "    dot02 = np.dot(v0, v2)\n",
    "    dot11 = np.dot(v1, v1)\n",
    "    dot12 = np.dot(v1, v2)\n",
    "    \n",
    "    denom = dot00*dot11 - dot01*dot01\n",
    "    \n",
    "    if denom == 0:\n",
    "        u = v = 0\n",
    "    else:\n",
    "        u = (dot11*dot02-dot01*dot12)/denom\n",
    "        v = (dot00*dot12-dot01*dot02)/denom\n",
    "    \n",
    "#     A = torch.stack((v0,v1)).t()\n",
    "#     B = v2[:,None]\n",
    "    \n",
    "#     X, LU = torch.solve(B,A)\n",
    "#     u = X[0,0]\n",
    "#     v = X[1,0]\n",
    "        \n",
    "#     weights = torch.tensor([1-u-v, u, v], dtype=torch.float32, requires_grad = True)\n",
    "    weights = np.array([1-u-v, u, v])\n",
    "    return weights\n",
    "\n",
    "def world_to_image(q_world, h, w):\n",
    "#     temp = np.array([w/2,h/2-h+1,0])\n",
    "#     q_image = (q_world + temp)*[1,-1,1]\n",
    "    q_image = q_world.clone()\n",
    "    \n",
    "    q_image[:,0] = q_image[:,0] + w/2\n",
    "    q_image[:,1] = q_image[:,1] + h/2\n",
    "    q_image[:,1] = h - q_image[:,1] - 1\n",
    "    \n",
    "    return q_image\n",
    "\n",
    "def rasterize(q, q_depth, tri_mesh_data, h, w):\n",
    "    depth_info = -math.inf*np.ones((h,w))\n",
    "#     depth_info = {}\n",
    "    tri_ind_info = -np.ones((h,w))\n",
    "    bary_wts_info = torch.zeros((h,w,3), requires_grad = True)\n",
    "    \n",
    "#     for i in range(h):\n",
    "#         for j in range(w):\n",
    "#             depth_info[(i,j)] = -math.inf\n",
    "#             bary_wts_info[(i,j)] = 0\n",
    "    q_n = q.data.cpu().numpy()\n",
    "    q_depth_n = q_depth.data.cpu().numpy()\n",
    "    for i in range(len(tri_mesh_data)):\n",
    "        print('Rasterizing triangle: ', i+1)\n",
    "        tri_ver_ind = tri_mesh_data[i,:]\n",
    "        \n",
    "        umin = max(int(np.ceil(np.min(q_n[tri_ver_ind, 0]))), 0) #torch.min(lmks_2d[:,0])\n",
    "        umax = min(int(np.floor(np.max(q_n[tri_ver_ind, 0]))), w-1) #torch.max(lmks_2d[:,0])\n",
    "        \n",
    "        vmin = max(int(np.ceil(np.min(q_n[tri_ver_ind, 1]))), 0) #torch.min(lmks_2d[:,0])\n",
    "        vmax = min(int(np.floor(np.max(q_n[tri_ver_ind, 1]))), h-1)\n",
    "        \n",
    "        if umax<umin or vmax<vmin:\n",
    "            continue\n",
    "        else:\n",
    "            for u in range(umin, umax+1):\n",
    "                for v in range(vmin, vmax+1):\n",
    "                    weights = barycentric_weights([u, v], q_n[tri_ver_ind, :])\n",
    "                    if (weights<0).all():\n",
    "                        continue\n",
    "                    else:\n",
    "                        depth = np.dot(weights, q_depth_n[tri_ver_ind])\n",
    "                        if depth > depth_info[v,u]:\n",
    "                            depth_info[v,u] = depth\n",
    "                            tri_ind_info[v,u] = i\n",
    "                            bary_wts_info[v,u,:] = torch.tensor(weights, requires_grad=True)\n",
    "                            \n",
    "    return tri_ind_info, bary_wts_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cartesian to spherical coordinates'''\n",
    "def cart2sph(n):\n",
    "#     phi = np.arctan2(n[1],n[0]) #arctan(y/x)\n",
    "#     theta = np.arccos(n[2]) #arccos(z)\n",
    "    if torch.is_tensor(n):\n",
    "        norm = n.cpu().detach().numpy()\n",
    "    else:\n",
    "        norm = n\n",
    "    phi = np.arctan2(norm[1],norm[0])\n",
    "    theta = np.arccos(norm[2])\n",
    "    return torch.tensor([phi, theta], dtype=torch.float32, requires_grad = True)\n",
    "\n",
    "'''Calculate normal of triangle for each pixel based on underlying triangle index'''\n",
    "def calculate_normal(tri_ind_info, tri_mesh_data, centroid, q, h, w):\n",
    "    normal_xyz = np.zeros((h, w, 3))\n",
    "    normal_sph = torch.zeros((h, w, 2), requires_grad = True)\n",
    "    cent = centroid.data.cpu().numpy()\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            tri_ver = q[tri_mesh_data[tri_ind_info[i, j]-1, :],:].data.cpu().numpy()\n",
    "            a = tri_ver[0,:]\n",
    "            b = tri_ver[1,:]\n",
    "            c = tri_ver[2,:]\n",
    "            normal_xyz[i,j,:] = np.cross(a-b, b-c)/np.linalg.norm(np.cross(a-b, b-c))\n",
    "            if np.dot(np.mean(tri_ver, 0)-cent, normal_xyz[i,j,:])<0:\n",
    "                normal_xyz[i,j,:] *= -1\n",
    "            normal_sph[i,j,:] = cart2sph(normal_xyz[i,j,:])\n",
    "    return normal_sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPointInTri(point, tri_points):\n",
    "    ''' Judge whether the point is in the triangle\n",
    "    Method:\n",
    "        http://blackpawn.com/texts/pointinpoly/\n",
    "    Args:\n",
    "        point: (2,). [u, v] or [x, y] \n",
    "        tri_points: (3 vertices, 2 coords). three vertices(2d points) of a triangle. \n",
    "    Returns:\n",
    "        bool: true for in triangle\n",
    "    '''\n",
    "    tp = tri_points\n",
    "\n",
    "    # vectors\n",
    "    v0 = tp[2,:] - tp[0,:]\n",
    "    v1 = tp[1,:] - tp[0,:]\n",
    "    v2 = point - tp[0,:]\n",
    "#     A = torch.stack((v0,v1)).t()\n",
    "#     B = v2[:,None]\n",
    "\n",
    "#     X = torch.inverse(A)@B\n",
    "\n",
    "#     u = X[0,0]\n",
    "#     v = X[1,0]\n",
    "    # dot products\n",
    "    dot00 = np.dot(v0, v0)\n",
    "    dot01 = np.dot(v0, v1)\n",
    "    dot02 = np.dot(v0, v2)\n",
    "    dot11 = np.dot(v1, v1)\n",
    "    dot12 = np.dot(v1, v2)\n",
    "\n",
    "    # barycentric coordinates\n",
    "    if dot00*dot11 - dot01*dot01 == 0:\n",
    "        inverDeno = 0\n",
    "    else:\n",
    "        inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "    u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "    v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "    # check if point in triangle\n",
    "    return (u >= 0) & (v >= 0) & (u + v < 1)\n",
    "\n",
    "'''To estimate the barycentric weights of a point given that it is inside a triangle\n",
    "    The barycentric weights are used later to estimate albedo by barycentric interpolation'''\n",
    "def get_point_weight(point, tri_points):\n",
    "    ''' Get the weights of the position\n",
    "    Methods: https://gamedev.stackexchange.com/questions/23743/whats-the-most-efficient-way-to-find-barycentric-coordinates\n",
    "     -m1.compute the area of the triangles formed by embedding the point P inside the triangle\n",
    "     -m2.Christer Ericson's book \"Real-Time Collision Detection\". faster.(used)\n",
    "    Args:\n",
    "        point: (2,). [u, v] or [x, y] \n",
    "        tri_points: (3 vertices, 2 coords). three vertices(2d points) of a triangle. \n",
    "    Returns:\n",
    "        w0: weight of v0\n",
    "        w1: weight of v1\n",
    "        w2: weight of v3\n",
    "     '''\n",
    "    tp = tri_points\n",
    "    # vectors\n",
    "    v0 = tp[2,:] - tp[0,:]\n",
    "    v1 = tp[1,:] - tp[0,:]\n",
    "    v2 = point - tp[0,:]\n",
    "    \n",
    "#     A = torch.stack((v0,v1)).t()\n",
    "#     B = v2[:,None]\n",
    "    \n",
    "#     X = torch.inverse(A)@B\n",
    "#     u = X[0,0]\n",
    "#     v = X[1,0]\n",
    "#     dot products\n",
    "    dot00 = np.dot(v0, v0)\n",
    "    dot01 = np.dot(v0, v1)\n",
    "    dot02 = np.dot(v0, v2)\n",
    "    dot11 = np.dot(v1, v1)\n",
    "    dot12 = np.dot(v1, v2)\n",
    "\n",
    "    # barycentric coordinates\n",
    "    if dot00*dot11 - dot01*dot01 == 0:\n",
    "        inverDeno = 0\n",
    "    else:\n",
    "        inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "    u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "    v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "   \n",
    "    w0 = 1 - u - v\n",
    "    w1 = v\n",
    "    w2 = u\n",
    "    return w0,w1,w2\n",
    "\n",
    "'''Rasterization to find underlying triangle index and barycentrics weights of each pixel'''\n",
    "def rasterize_triangles(vertices, triangles, h, w):\n",
    "    ''' \n",
    "    Args:\n",
    "        vertices: [nver, 3]\n",
    "        triangles: [ntri, 3]\n",
    "        h: height\n",
    "        w: width\n",
    "    Returns:\n",
    "        depth_buffer: [h, w] saves the depth, here, the bigger the z, the fronter the point.\n",
    "        triangle_buffer: [h, w] saves the tri id(-1 for no triangle). \n",
    "        barycentric_weight: [h, w, 3] saves corresponding barycentric weight.\n",
    "\n",
    "    # Each triangle has 3 vertices & Each vertex has 3 coordinates x, y, z.\n",
    "    # h, w is the size of rendering\n",
    "    '''\n",
    "    # initial \n",
    "    depth_buffer = torch.zeros([h, w]) - 999999. #+ torch.min(vertices[2,:]) - 999999. # set the initial z to the farest position\n",
    "    triangle_buffer = torch.zeros([h, w], dtype = torch.int32) - 1  # if tri id = -1, the pixel has no triangle correspondance\n",
    "    barycentric_weight = torch.zeros([h, w, 3], dtype = torch.float32)  # \n",
    "    \n",
    "#     for i in range(h):\n",
    "#         for j in range(w):\n",
    "#             depth_buffer[(i,j)] = -math.inf\n",
    "#             barycentric_weight[(i,j)] = 0\n",
    "    ver = vertices.data.cpu().numpy()\n",
    "    for i in range(triangles.shape[0]):\n",
    "        print('Rasterzing: ',i+1)\n",
    "        tri = triangles[i, :] # 3 vertex indices\n",
    "\n",
    "        # the inner bounding box\n",
    "        umin = max(int(np.ceil(np.min(ver[tri, 0]))), 0)\n",
    "        umax = min(int(np.floor(np.max(ver[tri, 0]))), w-1)\n",
    "\n",
    "        vmin = max(int(np.ceil(np.min(ver[tri, 1]))), 0)\n",
    "        vmax = min(int(np.floor(np.max(ver[tri, 1]))), h-1)\n",
    "\n",
    "        if umax<umin or vmax<vmin:\n",
    "            continue\n",
    "\n",
    "        for u in range(umin, umax+1):\n",
    "            for v in range(vmin, vmax+1):\n",
    "                if not isPointInTri([u, v], ver[tri, :2]): \n",
    "                    continue\n",
    "                w0, w1, w2 = get_point_weight([u, v], ver[tri, :2]) # barycentric weight\n",
    "                point_depth = w0*vertices[tri[0], 2] + w1*vertices[tri[1], 2] + w2*vertices[tri[2], 2]\n",
    "                if point_depth > depth_buffer[v, u]:\n",
    "                    depth_buffer[(v, u)] = point_depth\n",
    "                    triangle_buffer[v, u] = i\n",
    "                    barycentric_weight[v, u, :] = torch.tensor([w0, w1, w2], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    return triangle_buffer, barycentric_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to render image given 3D vertices, albedo and spherical harmonic coefficients for lighting'''\n",
    "def render_color_image(q, albedo, tri_mesh_data, gamma, h, w):\n",
    "    image = torch.zeros((h,w,3), dtype=torch.float32, requires_grad = True)\n",
    "    alb = torch.zeros((h,w,3), dtype=torch.float32, requires_grad = True)\n",
    "    centroid = torch.mean(q,0)\n",
    "    \n",
    "    st = time()\n",
    "#     tri_ind_info, bary_wts_info = rasterize(q[:,:2], q[:,2], tri_mesh_data, h, w)\n",
    "    tri_ind_info, bary_wts_info = rasterize_triangles(q, tri_mesh_data, h, w)\n",
    "    print('Rasterization Done!- %f seconds' %(time()-st))\n",
    "    \n",
    "    n_sph = calculate_normal(tri_ind_info, tri_mesh_data, centroid, q, h, w)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            sh_func = sh_basis(n_sph[i,j,:])\n",
    "            alb[i,j,:] = albedo[tri_mesh_data[tri_ind_info[i, j]-1, :],:].t()@bary_wts_info[i,j,:]\n",
    "            image[i,j,:] = alb[i,j,:]*(gamma.t()@sh_func.squeeze())\n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Input image'''\n",
    "I_in = plt.imread('Dataset/300W-Convert/300W-Original/afw/134212_1.jpg')\n",
    "I_in=torch.tensor(I_in[144:400,700:956,:],dtype = torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Jacobian matrix estimation'''\n",
    "def compute_jacobian(inputs, output):\n",
    "    \"\"\"\n",
    "    :param inputs: Batch X Size (e.g. Depth X Width X Height)\n",
    "    :param output: Batch X Classes\n",
    "    :return: jacobian: Batch X Classes X Size\n",
    "    \"\"\"\n",
    "    assert inputs.requires_grad\n",
    "\n",
    "    num_classes = output.shape[0]\n",
    "\n",
    "    jacobian = torch.zeros((num_classes, inputs.shape[0], inputs.shape[1]))\n",
    "    grad_output = torch.zeros(output.shape)\n",
    "    if inputs.is_cuda:\n",
    "        grad_output = grad_output.cuda()\n",
    "        jacobian = jacobian.cuda()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        zero_gradients(inputs)\n",
    "        grad_output.zero_()\n",
    "        grad_output[i] = 1\n",
    "        output.backward(grad_output, retain_graph=True)\n",
    "        jacobian[i] = inputs.grad.data\n",
    "\n",
    "    return jacobian.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=w=256\n",
    "chi = torch.rand(312,1,requires_grad = True, dtype=torch.float32)\n",
    "# t = torch.zeros(3,1, requires_grad = True, dtype=torch.float32)\n",
    "count = 1\n",
    "chi_prev = chi\n",
    "while True:\n",
    "    print(\"Iteration No: \", count)\n",
    "    \n",
    "    al_id = chi_prev[0:100]\n",
    "    al_exp = chi_prev[100:179]\n",
    "    al_alb = chi_prev[179:279]\n",
    "    [s, pitch, yaw, roll] = chi_prev[279:283,0]\n",
    "    t = chi_prev[283:285]\n",
    "    r = chi_prev[285:]\n",
    "    gamma = torch.reshape(r,(3,9)).t()\n",
    "    \n",
    "    \n",
    "    p = p_mu + torch.matmul(A_id,al_id) + torch.matmul(A_exp,al_exp)\n",
    "    b = b_mu + torch.matmul(A_alb,al_alb)\n",
    "    vertex = torch.reshape(p, (no_of_ver, 3))\n",
    "    albedo = torch.reshape(b, (no_of_ver, 3))\n",
    "    \n",
    "    if count == 1:\n",
    "        s = 150/(torch.max(vertex) - torch.min(vertex))\n",
    "    \n",
    "    R = rot_mat(pitch, yaw, roll)\n",
    "    q_world = s*R@vertex.t() \n",
    "    q_world[:2,:] = q_world[:2,:] + t\n",
    "    q_image = world_to_image(q_world.t(), h, w) #Convert wirld coordinates to image coordinates\n",
    "    print('Rendering Image...')\n",
    "    st = time()\n",
    "\n",
    "    I_rend = render_color_image(q_image, albedo, tri_mesh_data, gamma, h, w)\n",
    "    print('Rendering Done! - %f seconds' %(time()-st) )\n",
    "    w_l = 100\n",
    "    w_r = 5e-5\n",
    "    \n",
    "    E_con_r = torch.reshape(I_rend - I_in,-1)#torch.tensor([np.sqrt(1/28241)*torch.norm(I_rend - I_in)], requires_grad = True)\n",
    "    E_lan_r = np.sqrt(w_l/68)*torch.reshape(lmks_2d - q_image[lmks_3d_ind[0,:],:2],(-1,))\n",
    "    E_reg_r = np.sqrt(w_r)*torch.cat((al_id/std_id,al_alb/std_alb,al_exp/std_exp))\n",
    "\n",
    "    E = torch.cat((E_con_r,E_lan_r,E_reg_r[:,0]))\n",
    "    J = compute_jacobian(chi_prev,E)\n",
    "    chi_next = chi_prev.detach() - torch.pinverse(J.t()@J)@J.t()@E.detach().unsqueeze(1)\n",
    "    increment = torch.norm(chi_next - chi_prev)\n",
    "    obj_func_loss = torch.norm(E)**2\n",
    "    chi_prev = chi_next.clone()\n",
    "    chi_prev.requires_grad = True\n",
    "    del E\n",
    "    count=count+1\n",
    "    print('Increment: ', increment)\n",
    "    print('Loss: ', obj_func_loss)\n",
    "    if obj_func_loss<10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.view_init(-45,45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(q_world[0,:].cpu().detach(), q_world[1,:].cpu().detach(), q_world[2,:].cpu().detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
